{
  "config": {
    "step": {
      "user": {
        "title": "OpenRouter API Configuration",
        "description": "Enter your OpenRouter API key. You can get one at {docs_url}",
        "data": {
          "api_key": "API Key"
        }
      },
      "model": {
        "title": "Model Configuration",
        "description": "Select any OpenRouter model. You can enter a custom model ID or choose from suggestions.\n\nProvider selection will be shown in the next step based on available endpoints for your chosen model.",
        "data": {
          "model": "Model (e.g. anthropic/claude-3-haiku)",
          "temperature": "Temperature (0 = precise, 1 = creative)",
          "max_tokens": "Maximum response tokens"
        }
      },
      "provider": {
        "title": "Provider Selection",
        "description": "Select a provider for **{model}**.\n\nFound **{provider_count}** providers offering this model. Providers are sorted by price (cheapest first).\n\n**Prompt Caching:** For caching, select a specific provider (not 'auto'). See [OpenRouter docs]({caching_docs_url}).",
        "data": {
          "provider": "Provider"
        },
        "data_description": {
          "provider": "Choose 'Automatic' for best price, or select a specific provider for guaranteed routing."
        }
      },
      "behavior": {
        "title": "Behavior Settings",
        "description": "Configure how Smart Assist behaves",
        "data": {
          "language": "Response Language",
          "exposed_only": "Use only exposed entities",
          "confirm_critical": "Confirm critical actions (locks, alarms)",
          "max_history": "Maximum conversation history",
          "enable_web_search": "Enable web search (DuckDuckGo)",
          "enable_quick_actions": "Enable quick actions (bypass LLM for simple commands)",
          "enable_prompt_caching": "Enable prompt caching (reduces latency and cost)"
        }
      },
      "prompt": {
        "title": "Prompt Configuration",
        "description": "Customize the assistant's personality and behavior",
        "data": {
          "user_system_prompt": "Custom System Prompt",
          "task_system_prompt": "AI Task System Prompt",
          "task_enable_prompt_caching": "AI Task: Enable prompt caching",
          "task_enable_cache_warming": "AI Task: Enable cache warming"
        },
        "data_description": {
          "user_system_prompt": "Personality and instructions for interactive conversations.",
          "task_system_prompt": "Instructions for background AI tasks in automations.",
          "task_enable_prompt_caching": "Not recommended for tasks - they run in background and are not time-critical.",
          "task_enable_cache_warming": "Not recommended for tasks - they run in background and are not time-critical."
        }
      }
    },
    "error": {
      "invalid_api_key": "Invalid API key. Please check and try again.",
      "cannot_connect": "Cannot connect to OpenRouter API.",
      "unknown": "An unexpected error occurred."
    },
    "abort": {
      "already_configured": "Smart Assist is already configured."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Smart Assist - Model Settings",
        "description": "Configure your AI model and provider.",
        "data": {
          "model": "Model",
          "temperature": "Temperature",
          "max_tokens": "Maximum response tokens"
        },
        "data_description": {
          "model": "Select an OpenRouter model or enter a custom model ID."
        }
      },
      "provider": {
        "title": "Smart Assist - Provider",
        "description": "Select a provider for **{model}**.\n\nProviders are sorted by price (cheapest first).",
        "data": {
          "provider": "Provider"
        },
        "data_description": {
          "provider": "Choose 'Automatic' for best price, or select a specific provider for prompt caching."
        }
      },
      "behavior": {
        "title": "Smart Assist - Behavior",
        "description": "Configure assistant behavior and features.",
        "data": {
          "language": "Response Language",
          "exposed_only": "Use only exposed entities",
          "confirm_critical": "Confirm critical actions",
          "max_history": "Maximum conversation history",
          "enable_web_search": "Enable web search (DuckDuckGo)",
          "enable_quick_actions": "Enable quick actions (bypass LLM)"
        }
      },
      "caching": {
        "title": "Smart Assist - Caching",
        "description": "Configure prompt caching for reduced latency and cost.\n\nRequires a specific provider (not 'auto') and a supported model.",
        "data": {
          "enable_prompt_caching": "Enable prompt caching",
          "cache_ttl_extended": "Use extended cache TTL (longer cache lifetime)",
          "enable_cache_warming": "Enable cache warming (pre-warm cache periodically)",
          "cache_refresh_interval": "Cache refresh interval (minutes)"
        },
        "data_description": {
          "enable_prompt_caching": "Reduces latency and cost by caching system prompts.",
          "cache_ttl_extended": "Some providers support extended cache lifetime.",
          "enable_cache_warming": "Periodically refresh cache to maintain low latency.",
          "cache_refresh_interval": "How often to refresh the cache (1-55 minutes)."
        }
      },
      "advanced": {
        "title": "Smart Assist - Advanced",
        "description": "Advanced response formatting and prompts.",
        "data": {
          "clean_responses": "Clean responses (remove markdown formatting)",
          "ask_followup": "Ask follow-up questions",
          "user_system_prompt": "Custom System Prompt",
          "task_system_prompt": "AI Task System Prompt",
          "task_enable_prompt_caching": "AI Task: Enable prompt caching",
          "task_enable_cache_warming": "AI Task: Enable cache warming",
          "debug_logging": "Enable debug logging"
        },
        "data_description": {
          "clean_responses": "Remove markdown symbols like ** and * from responses.",
          "ask_followup": "Assistant asks clarifying questions when needed.",
          "user_system_prompt": "Additional instructions for the AI assistant.",
          "task_system_prompt": "Instructions for background AI tasks in automations.",
          "task_enable_prompt_caching": "Not recommended - background tasks are not time-critical.",
          "task_enable_cache_warming": "Not recommended - background tasks are not time-critical.",
          "debug_logging": "Enable verbose logging for troubleshooting (logs to Home Assistant)."
        }
      }
    }
  }
}