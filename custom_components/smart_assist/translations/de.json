{
  "config": {
    "step": {
      "user": {
        "title": "LLM Anbieter waehlen",
        "description": "Waehle deinen bevorzugten LLM Anbieter.\n\n**Groq**: Ultraschnelle Inferenz mit automatischem Caching (empfohlen)\n**OpenRouter**: Zugang zu allen Modellen (Claude, GPT-4, Llama, etc.)\n**Ollama**: Lokale, private Inferenz (keine Cloud, kein API Key noetig)",
        "data": {
          "llm_provider": "LLM Anbieter"
        }
      },
      "api_key": {
        "title": "API Key",
        "description": "Gib deinen API Key ein. Du kannst einen bei {docs_url} erstellen.",
        "data": {
          "api_key": "OpenRouter API Key",
          "groq_api_key": "Groq API Key",
          "ollama_url": "Ollama Server URL",
          "ollama_model": "Ollama Modell",
          "ollama_keep_alive": "Modell geladen halten",
          "ollama_num_ctx": "Kontextfenstergroesse",
          "ollama_timeout": "Anfrage-Timeout (Sekunden)"
        },
        "data_description": {
          "ollama_url": "URL deines Ollama Servers (Standard: http://localhost:11434)",
          "ollama_model": "Waehle ein Modell aus deiner lokalen Ollama Installation",
          "ollama_keep_alive": "Wie lange das Modell im Speicher bleiben soll (-1 = dauerhaft)",
          "ollama_num_ctx": "Kontextfenstergroesse in Token (Standard: 8192)",
          "ollama_timeout": "Maximale Wartezeit fuer eine Antwort (Standard: 120s)"
        }
      },
      "reconfigure": {
        "title": "API Keys & Ollama Einstellungen",
        "description": "Aktualisiere deine API Keys und Ollama Einstellungen. Lasse API Key Felder leer um bestehende Werte zu behalten.\n\n**API Key Status:**\n- Groq: {groq_status}\n- OpenRouter: {openrouter_status}\n- Ollama: {ollama_status}",
        "data": {
          "groq_api_key": "Groq API Key",
          "api_key": "OpenRouter API Key",
          "ollama_url": "Ollama Server URL",
          "ollama_num_ctx": "Ollama: Kontextfenstergroesse",
          "ollama_keep_alive": "Ollama: Modell geladen halten",
          "ollama_timeout": "Ollama: Timeout (Sekunden)"
        },
        "data_description": {
          "groq_api_key": "Gib einen neuen Groq API Key ein oder lasse das Feld leer um den aktuellen zu behalten.",
          "api_key": "Gib einen neuen OpenRouter API Key ein oder lasse das Feld leer um den aktuellen zu behalten.",
          "ollama_url": "Gib eine neue Ollama URL ein oder lasse das Feld leer um die aktuelle zu behalten.",
          "ollama_num_ctx": "Kontextfenstergroesse in Token. Groessere Werte erlauben mehr Kontext, brauchen aber mehr RAM.",
          "ollama_keep_alive": "Wie lange das Modell nach einer Anfrage im Speicher geladen bleibt.",
          "ollama_timeout": "Maximale Wartezeit auf Antwort von Ollama (in Sekunden)."
        }
      }
    },
    "error": {
      "invalid_api_key": "Ungueltiger OpenRouter API Key. Bitte ueberpruefen und erneut versuchen.",
      "invalid_groq_api_key": "Ungueltiger Groq API Key. Bitte ueberpruefen und erneut versuchen.",
      "ollama_connection_failed": "Verbindung zum Ollama Server nicht moeglich. Stelle sicher, dass Ollama unter der angegebenen URL laeuft.",
      "groq_api_key_required": "Groq API Key wird fuer den Groq Provider benoetigt.",
      "openrouter_api_key_required": "OpenRouter API Key wird fuer den OpenRouter Provider benoetigt.",
      "ollama_not_configured": "Ollama ist nicht konfiguriert. Bitte fuege Ollama in den Haupteinstellungen hinzu.",
      "no_api_key": "Mindestens ein API Key (OpenRouter oder Groq) ist erforderlich.",
      "cannot_connect": "Verbindung zur API nicht moeglich.",
      "unknown": "Ein unerwarteter Fehler ist aufgetreten."
    },
    "abort": {
      "already_configured": "Smart Assist ist bereits konfiguriert."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Smart Assist Einstellungen",
        "description": "Konfiguriere globale Einstellungen fuer Smart Assist.",
        "data": {
          "debug_logging": "Debug-Logging aktivieren",
          "enable_cancel_handler": "Cancel Intent Handler"
        },
        "data_description": {
          "debug_logging": "Aktiviert ausfuehrliches Logging zur Fehlersuche.",
          "enable_cancel_handler": "Gibt eine gesprochene Bestaetigung zurueck wenn der Nutzer 'Abbrechen' oder 'Vergiss es' sagt. Behebt das Haengenbleiben von Sprachsatelliten bei leeren Abbruch-Antworten. Nutzt die LLM fuer eine natuerliche Antwort."
        }
      }
    }
  },
  "config_subentries": {
    "conversation": {
      "entry_type": "Konversations-Agent",
      "initiate_flow": {
        "user": "Konversations-Agent hinzufuegen",
        "reconfigure": "Konversations-Agent rekonfigurieren"
      },
      "step": {
        "user": {
          "title": "LLM Provider Auswahl",
          "description": "Waehle den LLM Provider fuer diesen Konversations-Agenten.\n\n**OpenRouter**: Zugang zu allen Modellen (Claude, GPT-4, Llama, etc.) ueber eine einheitliche API.\n**Groq**: Direkte Verbindung fuer ultraschnelle Inferenz mit automatischem Caching.\n**Ollama**: Lokale, private Inferenz ohne Cloud-Abhaengigkeit.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          },
          "data_description": {
            "llm_provider": "Waehle OpenRouter fuer Modellvielfalt, Groq fuer schnellste Inferenz, oder Ollama fuer lokalen Datenschutz.",
            "groq_api_key": "Gib deinen Groq API Key ein (erhaltbar bei console.groq.com)."
          }
        },
        "model": {
          "title": "Modellauswahl",
          "description": "Waehle das KI-Modell fuer diesen Konversations-Agenten.",
          "data": {
            "model": "Modell"
          },
          "data_description": {
            "model": "Waehle ein Modell oder gib eine eigene Modell-ID ein."
          }
        },
        "settings": {
          "title": "Agent Einstellungen",
          "description": "Konfiguriere Provider und Verhaltenseinstellungen fuer diesen Konversations-Agenten.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur (0 = praezise, 1 = kreativ)",
            "max_tokens": "Maximale Antwort-Tokens",
            "max_history": "Maximale Konversationshistorie",
            "language": "Antwortsprache",
            "clean_responses": "Antworten fuer Sprachausgabe bereinigen",
            "ask_followup": "Rueckfragen stellen",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "entity_discovery_mode": "Entity Discovery Modus",
            "confirm_critical": "Kritische Aktionen bestaetigen (Schloesser, Alarme)",
            "tool_max_retries": "Maximale Tool-Wiederholungen",
            "tool_latency_budget_ms": "Tool-Latenzbudget (ms)",
            "enable_web_search": "Websuche aktivieren (DuckDuckGo)",
            "calendar_context": "Proaktive Kalender-Erinnerungen",
            "enable_memory": "Benutzer-Gedaechtnis & Personalisierung aktivieren",
            "enable_agent_memory": "Agent Auto-Learning aktivieren",
            "enable_presence_heuristic": "Praesenzbasierte Benutzererkennung aktivieren",
            "enable_cache_warming": "Automatisches Cache-Warming aktivieren",
            "cache_refresh_interval": "Cache-Aktualisierungsintervall (Minuten)",
            "cancel_intent_agent": "Als Cancel Intent Handler verwenden"
          },
          "data_description": {
            "provider": "Nur OpenRouter: Waehle einen spezifischen Provider oder 'Automatisch' fuer bestes Preis-Routing.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort.",
            "max_history": "Anzahl vorheriger Nachrichten, die als Kontext behalten werden. Hoehere Werte verbrauchen mehr Tokens.",
            "language": "'auto' = nutzt HA-Sprache. Oder beliebige Sprache eingeben (z.B. 'French', 'es-ES', 'Japanese').",
            "clean_responses": "Macht Antworten TTS-freundlich durch Entfernen von Emojis, Markdown-Formatierung und URLs.",
            "ask_followup": "Wenn aktiviert, bietet der Assistent nach Aktionen weitere Hilfe an.",
            "exposed_only": "Steuert nur Entities, die in Home Assistant explizit freigegeben sind. Deaktivieren fuer Zugriff auf alle Entities.",
            "entity_discovery_mode": "Full Index: Alle Entities im Prompt (ideal fuer kleine Setups). Smart Discovery: Keine Entity-Liste -- Entities werden per Tool-Aufrufe on-demand entdeckt (spart Tokens bei grossen Setups).",
            "confirm_critical": "Fragt vor dem Sperren von Tueren, Aktivieren von Alarmen oder anderen sicherheitskritischen Aktionen nach Bestaetigung.",
            "tool_max_retries": "Maximale Anzahl an Wiederholungen fuer fehlgeschlagene Tool-Aufrufe pro Anfrage.",
            "tool_latency_budget_ms": "Timeout-Budget pro Tool in Millisekunden. Zeitueberschreitungen werden als Fehler gewertet.",
            "enable_web_search": "Erlaubt dem Assistenten, ueber DuckDuckGo nach aktuellen Informationen im Web zu suchen.",
            "calendar_context": "Automatisch auf anstehende Termine hinweisen. Hinweis: Erhoehter Token-Verbrauch.",
            "enable_memory": "Erlaubt dem Assistenten, sich Benutzer-Praeferenzen, Namen und Anweisungen ueber Gespraeche hinweg zu merken.",
            "enable_agent_memory": "Erlaubt dem Assistenten, aus Interaktionen zu lernen und eigene Beobachtungen zu speichern (Muster, Gewohnheiten, Systemerkenntnisse). Erfordert aktiviertes Gedaechtnis.",
            "enable_presence_heuristic": "Erkennt automatisch anhand der Anwesenheit, welcher Benutzer spricht. Funktioniert nur, wenn genau eine Person zuhause ist.",
            "enable_cache_warming": "Haelt den Prompt-Cache durch periodische Anfragen warm. Verursacht geringe zusaetzliche API-Kosten.",
            "cache_refresh_interval": "Wie oft der Cache aktualisiert wird (in Minuten). Unter dem Cache-TTL setzen.",
            "cancel_intent_agent": "Diesen Agenten fuer die gesprochene Abbruch-Bestaetigung verwenden. Nur ein Agent sollte diese Option aktiviert haben. Wenn keiner ausgewaehlt ist, wird der erste verfuegbare Agent verwendet."
          }
        },
        "prompt": {
          "title": "System Prompt",
          "description": "Passe die Persoenlichkeit und das Verhalten des Assistenten an.",
          "data": {
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "user_system_prompt": "Persoenlichkeit und Anweisungen fuer diesen Konversations-Agenten."
          }
        },
        "reconfigure": {
          "title": "Agent rekonfigurieren - LLM Provider",
          "description": "Waehle den LLM Provider fuer diesen Agenten.\n\nNach der Bestaetigung kannst du Modell und andere Einstellungen aktualisieren.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          }
        },
        "reconfigure_model": {
          "title": "Agent rekonfigurieren - Modell",
          "description": "Waehle ein neues Modell fuer diesen Agenten.",
          "data": {
            "model": "Modell"
          }
        },
        "reconfigure_settings": {
          "title": "Agent rekonfigurieren - Einstellungen",
          "description": "Provider und Verhaltenseinstellungen fuer diesen Konversations-Agenten aktualisieren.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur",
            "max_tokens": "Maximale Antwort-Tokens",
            "max_history": "Maximale Konversationshistorie",
            "language": "Antwortsprache",
            "clean_responses": "Antworten fuer Sprachausgabe bereinigen",
            "ask_followup": "Rueckfragen stellen",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "entity_discovery_mode": "Entity Discovery Modus",
            "confirm_critical": "Kritische Aktionen bestaetigen",
            "tool_max_retries": "Maximale Tool-Wiederholungen",
            "tool_latency_budget_ms": "Tool-Latenzbudget (ms)",
            "enable_web_search": "Websuche aktivieren",
            "calendar_context": "Proaktive Kalender-Erinnerungen",
            "enable_memory": "Benutzer-Gedaechtnis aktivieren",
            "enable_agent_memory": "Agent Auto-Learning aktivieren",
            "enable_presence_heuristic": "Praesenzbasierte Benutzererkennung",
            "enable_cache_warming": "Cache-Warming aktivieren",
            "cache_refresh_interval": "Cache-Aktualisierungsintervall",
            "cancel_intent_agent": "Als Cancel Intent Handler verwenden",
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "provider": "Nur OpenRouter: Waehle einen spezifischen Provider oder 'Automatisch' fuer bestes Preis-Routing.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort.",
            "language": "'auto' = nutzt HA-Sprache. Oder beliebige Sprache eingeben (z.B. 'French', 'es-ES', 'Japanese').",
            "exposed_only": "Steuert nur Entities, die in Home Assistant explizit freigegeben sind. Deaktivieren fuer Zugriff auf alle Entities.",
            "entity_discovery_mode": "Full Index: Alle Entities im Prompt (ideal fuer kleine Setups). Smart Discovery: Keine Entity-Liste -- Entities werden per Tool-Aufrufe on-demand entdeckt (spart Tokens bei grossen Setups).",
            "confirm_critical": "Fragt vor dem Sperren von Tueren, Aktivieren von Alarmen oder anderen sicherheitskritischen Aktionen nach Bestaetigung.",
            "tool_max_retries": "Maximale Anzahl an Wiederholungen fuer fehlgeschlagene Tool-Aufrufe pro Anfrage.",
            "tool_latency_budget_ms": "Timeout-Budget pro Tool in Millisekunden. Zeitueberschreitungen werden als Fehler gewertet.",
            "max_history": "Anzahl vorheriger Nachrichten, die als Kontext behalten werden. Hoehere Werte verbrauchen mehr Tokens.",
            "enable_web_search": "Erlaubt dem Assistenten, ueber DuckDuckGo nach aktuellen Informationen im Web zu suchen.",
            "enable_cache_warming": "Haelt den Prompt-Cache durch periodische Anfragen warm. Verursacht geringe zusaetzliche API-Kosten.",
            "cache_refresh_interval": "Wie oft der Cache aktualisiert wird (in Minuten). Unter dem Cache-TTL setzen.",
            "clean_responses": "Macht Antworten TTS-freundlich durch Entfernen von Emojis, Markdown-Formatierung und URLs.",
            "ask_followup": "Wenn aktiviert, bietet der Assistent nach Aktionen weitere Hilfe an.",
            "calendar_context": "Automatisch auf anstehende Termine hinweisen. Hinweis: Erhoehter Token-Verbrauch.",
            "enable_memory": "Erlaubt dem Assistenten, sich Benutzer-Praeferenzen, Namen und Anweisungen ueber Gespraeche hinweg zu merken.",
            "enable_agent_memory": "Erlaubt dem Assistenten, aus Interaktionen zu lernen und eigene Beobachtungen zu speichern (Muster, Gewohnheiten, Systemerkenntnisse). Erfordert aktiviertes Gedaechtnis.",
            "enable_presence_heuristic": "Erkennt automatisch anhand der Anwesenheit, welcher Benutzer spricht. Funktioniert nur, wenn genau eine Person zuhause ist.",
            "user_system_prompt": "Persoenlichkeit und Anweisungen fuer diesen Konversations-Agenten.",
            "cancel_intent_agent": "Diesen Agenten fuer die gesprochene Abbruch-Bestaetigung verwenden. Nur ein Agent sollte diese Option aktiviert haben. Wenn keiner ausgewaehlt ist, wird der erste verfuegbare Agent verwendet."
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Einstellungen erfolgreich aktualisiert.",
        "no_api_keys_configured": "Keine API-Schluessel konfiguriert. Bitte fuege mindestens einen API-Schluessel in den Haupteinstellungen hinzu."
      },
      "error": {
        "groq_api_key_required": "Groq API-Schluessel wird fuer den Groq Provider benoetigt.",
        "openrouter_api_key_required": "OpenRouter API-Schluessel wird fuer den OpenRouter Provider benoetigt.",
        "ollama_not_configured": "Ollama ist nicht konfiguriert. Bitte fuege Ollama in den Haupteinstellungen hinzu."
      }
    },
    "ai_task": {
      "entry_type": "AI Task",
      "initiate_flow": {
        "user": "AI Task hinzufuegen",
        "reconfigure": "AI Task rekonfigurieren"
      },
      "step": {
        "user": {
          "title": "LLM Provider Auswahl",
          "description": "Waehle den LLM Provider fuer diesen AI Task.\n\n**OpenRouter**: Zugang zu allen Modellen ueber eine einheitliche API.\n**Groq**: Direkte Verbindung fuer ultraschnelle Inferenz.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          },
          "data_description": {
            "llm_provider": "Waehle OpenRouter fuer Modellvielfalt oder Groq fuer schnellste Inferenz.",
            "groq_api_key": "Gib deinen Groq API Key ein (erhaltbar bei console.groq.com)."
          }
        },
        "model": {
          "title": "Modellauswahl",
          "description": "Waehle das KI-Modell fuer diesen Task.",
          "data": {
            "model": "Modell"
          },
          "data_description": {
            "model": "Waehle ein Modell oder gib eine eigene Modell-ID ein."
          }
        },
        "settings": {
          "title": "Task Einstellungen",
          "description": "Konfiguriere Provider und andere Einstellungen fuer diesen AI Task.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur (0 = praezise, 1 = kreativ)",
            "max_tokens": "Maximale Antwort-Tokens",
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "task_allow_control": "Steuerungsausfuehrung erlauben",
            "task_allow_lock_control": "Schloss-Steuerung erlauben",
            "task_system_prompt": "System Prompt",
            "task_enable_cache_warming": "Cache-Warming aktivieren"
          },
          "data_description": {
            "provider": "Nur OpenRouter: Waehle einen spezifischen Provider oder 'Automatisch' fuer bestes Preis-Routing.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort.",
            "language": "'auto' = nutzt HA-Sprache. Oder beliebige Sprache eingeben (z.B. 'French', 'es-ES', 'Japanese').",
            "task_system_prompt": "Anweisungen fuer diesen AI Task in Automationen.",
            "exposed_only": "Steuert nur Entities, die in Home Assistant explizit freigegeben sind. Deaktivieren fuer Zugriff auf alle Entities.",
            "task_allow_control": "Wenn deaktiviert, kann dieser AI Task keine control-Tool-Aufrufe ausfuehren.",
            "task_allow_lock_control": "Wenn deaktiviert, kann dieser AI Task keine lock.*-Entities steuern (gilt nur bei aktivierter Steuerungsausfuehrung).",
            "task_enable_cache_warming": "Nicht empfohlen - Hintergrund-Tasks sind nicht zeitkritisch."
          }
        },
        "reconfigure": {
          "title": "Task rekonfigurieren - LLM Provider",
          "description": "Waehle den LLM Provider fuer diesen Task.\n\nNach der Bestaetigung kannst du Modell und andere Einstellungen aktualisieren.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          }
        },
        "reconfigure_model": {
          "title": "Task rekonfigurieren - Modell",
          "description": "Waehle ein neues Modell fuer diesen AI Task.",
          "data": {
            "model": "Modell"
          }
        },
        "reconfigure_settings": {
          "title": "Task rekonfigurieren - Einstellungen",
          "description": "Provider und Verhaltenseinstellungen fuer diesen AI Task aktualisieren.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur",
            "max_tokens": "Maximale Antwort-Tokens",
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "task_allow_control": "Steuerungsausfuehrung erlauben",
            "task_allow_lock_control": "Schloss-Steuerung erlauben",
            "task_system_prompt": "System Prompt",
            "task_enable_cache_warming": "Cache-Warming aktivieren"
          },
          "data_description": {
            "provider": "Nur OpenRouter: Waehle einen spezifischen Provider oder 'Automatisch' fuer bestes Preis-Routing.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort.",
            "language": "'auto' = nutzt HA-Sprache. Oder beliebige Sprache eingeben (z.B. 'French', 'es-ES', 'Japanese').",
            "exposed_only": "Steuert nur Entities, die in Home Assistant explizit freigegeben sind. Deaktivieren fuer Zugriff auf alle Entities.",
            "task_system_prompt": "Anweisungen fuer diesen AI Task in Automationen.",
            "task_allow_control": "Wenn deaktiviert, kann dieser AI Task keine control-Tool-Aufrufe ausfuehren.",
            "task_allow_lock_control": "Wenn deaktiviert, kann dieser AI Task keine lock.*-Entities steuern (gilt nur bei aktivierter Steuerungsausfuehrung).",
            "task_enable_cache_warming": "Nicht empfohlen - Hintergrund-Tasks sind nicht zeitkritisch."
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Einstellungen erfolgreich aktualisiert.",
        "no_api_keys_configured": "Keine API-Schluessel konfiguriert. Bitte fuege mindestens einen API-Schluessel in den Haupteinstellungen hinzu."
      },
      "error": {
        "groq_api_key_required": "Groq API-Schluessel wird fuer den Groq Provider benoetigt.",
        "openrouter_api_key_required": "OpenRouter API-Schluessel wird fuer den OpenRouter Provider benoetigt.",
        "ollama_not_configured": "Ollama ist nicht konfiguriert. Bitte fuege Ollama in den Haupteinstellungen hinzu."
      }
    }
  },
  "selector": {
    "entity_discovery_mode": {
      "options": {
        "full_index": "Full Index (alle Entities im Prompt)",
        "smart_discovery": "Smart Discovery (on-demand, spart Tokens)"
      }
    }
  }
}
