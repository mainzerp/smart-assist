{
  "config": {
    "step": {
      "user": {
        "title": "OpenRouter API Konfiguration",
        "description": "Gib deinen OpenRouter API Key ein. Du kannst einen Key bei {docs_url} erstellen.\n\nNach der Einrichtung kannst du Konversations-Agenten oder AI Tasks ueber das Integrationsmen√º hinzufuegen.",
        "data": {
          "api_key": "API Key"
        }
      }
    },
    "error": {
      "invalid_api_key": "Ungueltiger API Key. Bitte ueberpruefen und erneut versuchen.",
      "cannot_connect": "Verbindung zur OpenRouter API nicht moeglich.",
      "unknown": "Ein unerwarteter Fehler ist aufgetreten."
    },
    "abort": {
      "already_configured": "Smart Assist ist bereits konfiguriert."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Smart Assist Einstellungen",
        "description": "Konfiguriere globale Einstellungen fuer Smart Assist.",
        "data": {
          "debug_logging": "Debug-Logging aktivieren"
        },
        "data_description": {
          "debug_logging": "Aktiviert ausfuehrliches Logging zur Fehlersuche."
        }
      }
    }
  },
  "config_subentries": {
    "conversation": {
      "initiate_flow": {
        "user": "Konversations-Agent hinzufuegen"
      },
      "step": {
        "user": {
          "title": "Modellauswahl",
          "description": "Waehle das KI-Modell fuer diesen Konversations-Agenten.\n\nProvider wird auf 'Automatisch' gesetzt. Kann spaeter ueber Rekonfigurieren geaendert werden.",
          "data": {
            "model": "Modell",
            "temperature": "Temperatur (0 = praezise, 1 = kreativ)",
            "max_tokens": "Maximale Antwort-Tokens"
          },
          "data_description": {
            "model": "Waehle ein OpenRouter-Modell oder gib eine eigene Modell-ID ein.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort."
          }
        },
        "behavior": {
          "title": "Verhaltenseinstellungen",
          "description": "Konfiguriere das Verhalten dieses Konversations-Agenten.",
          "data": {
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "confirm_critical": "Kritische Aktionen bestaetigen (Schloesser, Alarme)",
            "max_history": "Maximale Konversationshistorie",
            "enable_web_search": "Websuche aktivieren (DuckDuckGo)",
            "enable_prompt_caching": "Prompt Caching aktivieren (reduziert Latenz und Kosten)",
            "cache_ttl_extended": "Erweiterte Cache-Dauer (1 Stunde fuer Anthropic)",
            "enable_cache_warming": "Automatisches Cache-Warming aktivieren",
            "cache_refresh_interval": "Cache-Aktualisierungsintervall (Minuten)",
            "clean_responses": "Antworten fuer Sprachausgabe bereinigen",
            "ask_followup": "Rueckfragen stellen"
          },
          "data_description": {
            "cache_ttl_extended": "Aktiviert 1-Stunden-Cache statt 5 Minuten. Gilt nur fuer Anthropic-Modelle.",
            "enable_cache_warming": "Haelt den Prompt-Cache durch periodische Anfragen warm. Verursacht geringe zusaetzliche API-Kosten.",
            "cache_refresh_interval": "Wie oft der Cache aktualisiert wird (in Minuten). Unter dem Cache-TTL setzen.",
            "clean_responses": "Macht Antworten TTS-freundlich durch Entfernen von Emojis, Markdown-Formatierung und URLs.",
            "ask_followup": "Wenn aktiviert, bietet der Assistent nach Aktionen weitere Hilfe an."
          }
        },
        "prompt": {
          "title": "System Prompt",
          "description": "Passe die Persoenlichkeit und das Verhalten des Assistenten an.",
          "data": {
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "user_system_prompt": "Persoenlichkeit und Anweisungen fuer diesen Konversations-Agenten."
          }
        },
        "reconfigure": {
          "title": "Agent rekonfigurieren",
          "description": "Einstellungen fuer diesen Agenten aktualisieren.\n\nUm einen spezifischen Provider fuer Prompt Caching auszuwaehlen, waehle einen aus dem Provider-Dropdown.",
          "data": {
            "model": "Modell",
            "temperature": "Temperatur",
            "max_tokens": "Maximale Antwort-Tokens",
            "provider": "Provider",
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "confirm_critical": "Kritische Aktionen bestaetigen",
            "enable_prompt_caching": "Prompt Caching aktivieren",
            "cache_ttl_extended": "Erweiterte Cache-Dauer",
            "enable_cache_warming": "Cache-Warming aktivieren",
            "cache_refresh_interval": "Cache-Aktualisierungsintervall",
            "clean_responses": "Antworten fuer Sprachausgabe bereinigen",
            "ask_followup": "Rueckfragen stellen",
            "user_system_prompt": "System Prompt"
          }
        }
      }
    },
    "ai_task": {
      "initiate_flow": {
        "user": "AI Task hinzufuegen"
      },
      "step": {
        "user": {
          "title": "Modellauswahl",
          "description": "Waehle das KI-Modell fuer diesen Task.",
          "data": {
            "model": "Modell",
            "temperature": "Temperatur (0 = praezise, 1 = kreativ)",
            "max_tokens": "Maximale Antwort-Tokens"
          },
          "data_description": {
            "model": "Waehle ein OpenRouter-Modell oder gib eine eigene Modell-ID ein.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort."
          }
        },
        "settings": {
          "title": "Task Einstellungen",
          "description": "Konfiguriere diesen AI Task.",
          "data": {
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "task_system_prompt": "System Prompt",
            "task_enable_prompt_caching": "Prompt Caching aktivieren",
            "task_enable_cache_warming": "Cache-Warming aktivieren"
          },
          "data_description": {
            "task_system_prompt": "Anweisungen fuer diesen AI Task in Automationen.",
            "task_enable_prompt_caching": "Nicht empfohlen - Hintergrund-Tasks sind nicht zeitkritisch.",
            "task_enable_cache_warming": "Nicht empfohlen - Hintergrund-Tasks sind nicht zeitkritisch."
          }
        }
      }
    }
  }
}
