{
  "config": {
    "step": {
      "user": {
        "title": "API Konfiguration",
        "description": "Konfiguriere deine LLM API Keys. Mindestens ein API Key ist erforderlich.\n\n**OpenRouter** ({openrouter_url}): Zugang zu allen Modellen (Claude, GPT-4, Llama, etc.)\n**Groq** ({groq_url}): Ultraschnelle Inferenz mit automatischem Caching\n\nDu kannst beide konfigurieren fuer maximale Flexibilitaet.",
        "data": {
          "api_key": "OpenRouter API Key (optional)",
          "groq_api_key": "Groq API Key (optional)"
        },
        "data_description": {
          "api_key": "Hole deinen Key auf openrouter.ai/keys",
          "groq_api_key": "Hole deinen Key auf console.groq.com/keys"
        }
      }
    },
    "error": {
      "invalid_api_key": "Ungueltiger OpenRouter API Key. Bitte ueberpruefen und erneut versuchen.",
      "invalid_groq_api_key": "Ungueltiger Groq API Key. Bitte ueberpruefen und erneut versuchen.",
      "groq_api_key_required": "Groq API Key wird fuer den Groq Provider benoetigt.",
      "no_api_key": "Mindestens ein API Key (OpenRouter oder Groq) ist erforderlich.",
      "cannot_connect": "Verbindung zur API nicht moeglich.",
      "unknown": "Ein unerwarteter Fehler ist aufgetreten."
    },
    "abort": {
      "already_configured": "Smart Assist ist bereits konfiguriert."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Smart Assist Einstellungen",
        "description": "Konfiguriere globale Einstellungen fuer Smart Assist.",
        "data": {
          "debug_logging": "Debug-Logging aktivieren"
        },
        "data_description": {
          "debug_logging": "Aktiviert ausfuehrliches Logging zur Fehlersuche."
        }
      }
    }
  },
  "config_subentries": {
    "conversation": {
      "entry_type": "Konversations-Agent",
      "initiate_flow": {
        "user": "Konversations-Agent hinzufuegen",
        "reconfigure": "Konversations-Agent rekonfigurieren"
      },
      "step": {
        "user": {
          "title": "LLM Provider Auswahl",
          "description": "Waehle den LLM Provider fuer diesen Konversations-Agenten.\n\n**OpenRouter**: Zugang zu allen Modellen (Claude, GPT-4, Llama, etc.) ueber eine einheitliche API.\n**Groq**: Direkte Verbindung fuer ultraschnelle Inferenz mit automatischem Caching.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          },
          "data_description": {
            "llm_provider": "Waehle OpenRouter fuer Modellvielfalt oder Groq fuer schnellste Inferenz.",
            "groq_api_key": "Gib deinen Groq API Key ein (erhaltbar bei console.groq.com)."
          }
        },
        "model": {
          "title": "Modellauswahl",
          "description": "Waehle das KI-Modell fuer diesen Konversations-Agenten.",
          "data": {
            "model": "Modell"
          },
          "data_description": {
            "model": "Waehle ein Modell oder gib eine eigene Modell-ID ein."
          }
        },
        "settings": {
          "title": "Agent Einstellungen",
          "description": "Konfiguriere Provider und Verhaltenseinstellungen fuer diesen Konversations-Agenten.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur (0 = praezise, 1 = kreativ)",
            "max_tokens": "Maximale Antwort-Tokens",
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "confirm_critical": "Kritische Aktionen bestaetigen (Schloesser, Alarme)",
            "max_history": "Maximale Konversationshistorie",
            "enable_web_search": "Websuche aktivieren (DuckDuckGo)",
            "enable_prompt_caching": "Prompt Caching aktivieren (reduziert Latenz und Kosten)",
            "cache_ttl_extended": "Erweiterte Cache-Dauer (1 Stunde fuer Anthropic)",
            "enable_cache_warming": "Automatisches Cache-Warming aktivieren",
            "cache_refresh_interval": "Cache-Aktualisierungsintervall (Minuten)",
            "clean_responses": "Antworten fuer Sprachausgabe bereinigen",
            "ask_followup": "Rueckfragen stellen",
            "calendar_context": "Proaktive Kalender-Erinnerungen"
          },
          "data_description": {
            "provider": "Nur OpenRouter: Waehle einen spezifischen Provider oder 'Automatisch' fuer bestes Preis-Routing.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort.",
            "language": "Leer lassen fuer Auto-Erkennung (nutzt HA-Sprache). Oder beliebige Sprache eingeben (z.B. 'French', 'es-ES', 'Japanese').",
            "cache_ttl_extended": "Aktiviert 1-Stunden-Cache statt 5 Minuten. Gilt nur fuer Anthropic-Modelle.",
            "enable_cache_warming": "Haelt den Prompt-Cache durch periodische Anfragen warm. Verursacht geringe zusaetzliche API-Kosten.",
            "cache_refresh_interval": "Wie oft der Cache aktualisiert wird (in Minuten). Unter dem Cache-TTL setzen.",
            "clean_responses": "Macht Antworten TTS-freundlich durch Entfernen von Emojis, Markdown-Formatierung und URLs.",
            "ask_followup": "Wenn aktiviert, bietet der Assistent nach Aktionen weitere Hilfe an.",
            "calendar_context": "Automatisch auf anstehende Termine hinweisen. Hinweis: Erhoehter Token-Verbrauch."
          }
        },
        "prompt": {
          "title": "System Prompt",
          "description": "Passe die Persoenlichkeit und das Verhalten des Assistenten an.",
          "data": {
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "user_system_prompt": "Persoenlichkeit und Anweisungen fuer diesen Konversations-Agenten."
          }
        },
        "reconfigure": {
          "title": "Agent rekonfigurieren - LLM Provider",
          "description": "Waehle den LLM Provider fuer diesen Agenten.\n\nNach der Bestaetigung kannst du Modell und andere Einstellungen aktualisieren.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          }
        },
        "reconfigure_model": {
          "title": "Agent rekonfigurieren - Modell",
          "description": "Waehle ein neues Modell fuer diesen Agenten.",
          "data": {
            "model": "Modell"
          }
        },
        "reconfigure_settings": {
          "title": "Agent rekonfigurieren - Einstellungen",
          "description": "Provider und Verhaltenseinstellungen fuer diesen Konversations-Agenten aktualisieren.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur",
            "max_tokens": "Maximale Antwort-Tokens",
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "confirm_critical": "Kritische Aktionen bestaetigen",
            "max_history": "Maximale Konversationshistorie",
            "enable_web_search": "Websuche aktivieren",
            "enable_prompt_caching": "Prompt Caching aktivieren",
            "cache_ttl_extended": "Erweiterte Cache-Dauer",
            "enable_cache_warming": "Cache-Warming aktivieren",
            "cache_refresh_interval": "Cache-Aktualisierungsintervall",
            "clean_responses": "Antworten fuer Sprachausgabe bereinigen",
            "ask_followup": "Rueckfragen stellen",
            "calendar_context": "Proaktive Kalender-Erinnerungen",
            "user_system_prompt": "System Prompt"
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Einstellungen erfolgreich aktualisiert."
      }
    },
    "ai_task": {
      "entry_type": "AI Task",
      "initiate_flow": {
        "user": "AI Task hinzufuegen",
        "reconfigure": "AI Task rekonfigurieren"
      },
      "step": {
        "user": {
          "title": "LLM Provider Auswahl",
          "description": "Waehle den LLM Provider fuer diesen AI Task.\n\n**OpenRouter**: Zugang zu allen Modellen ueber eine einheitliche API.\n**Groq**: Direkte Verbindung fuer ultraschnelle Inferenz.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          },
          "data_description": {
            "llm_provider": "Waehle OpenRouter fuer Modellvielfalt oder Groq fuer schnellste Inferenz.",
            "groq_api_key": "Gib deinen Groq API Key ein (erhaltbar bei console.groq.com)."
          }
        },
        "model": {
          "title": "Modellauswahl",
          "description": "Waehle das KI-Modell fuer diesen Task.",
          "data": {
            "model": "Modell"
          },
          "data_description": {
            "model": "Waehle ein Modell oder gib eine eigene Modell-ID ein."
          }
        },
        "settings": {
          "title": "Task Einstellungen",
          "description": "Konfiguriere Provider und andere Einstellungen fuer diesen AI Task.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur (0 = praezise, 1 = kreativ)",
            "max_tokens": "Maximale Antwort-Tokens",
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "task_system_prompt": "System Prompt",
            "task_enable_prompt_caching": "Prompt Caching aktivieren",
            "task_enable_cache_warming": "Cache-Warming aktivieren"
          },
          "data_description": {
            "provider": "Nur OpenRouter: Waehle einen spezifischen Provider oder 'Automatisch' fuer bestes Preis-Routing.",
            "temperature": "Niedrigere Werte erzeugen konsistentere Ausgaben, hoehere Werte sind kreativer.",
            "max_tokens": "Maximale Anzahl von Tokens in der Antwort.",
            "language": "Leer lassen fuer Auto-Erkennung (nutzt HA-Sprache). Oder beliebige Sprache eingeben (z.B. 'French', 'es-ES', 'Japanese').",
            "task_system_prompt": "Anweisungen fuer diesen AI Task in Automationen.",
            "task_enable_prompt_caching": "Nicht empfohlen - Hintergrund-Tasks sind nicht zeitkritisch.",
            "task_enable_cache_warming": "Nicht empfohlen - Hintergrund-Tasks sind nicht zeitkritisch."
          }
        },
        "reconfigure": {
          "title": "Task rekonfigurieren - LLM Provider",
          "description": "Waehle den LLM Provider fuer diesen Task.\n\nNach der Bestaetigung kannst du Modell und andere Einstellungen aktualisieren.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          }
        },
        "reconfigure_model": {
          "title": "Task rekonfigurieren - Modell",
          "description": "Waehle ein neues Modell fuer diesen AI Task.",
          "data": {
            "model": "Modell"
          }
        },
        "reconfigure_settings": {
          "title": "Task rekonfigurieren - Einstellungen",
          "description": "Provider und Verhaltenseinstellungen fuer diesen AI Task aktualisieren.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperatur",
            "max_tokens": "Maximale Antwort-Tokens",
            "language": "Antwortsprache",
            "exposed_only": "Nur freigegebene Entities verwenden",
            "task_system_prompt": "System Prompt",
            "task_enable_prompt_caching": "Prompt Caching aktivieren",
            "task_enable_cache_warming": "Cache-Warming aktivieren"
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Einstellungen erfolgreich aktualisiert."
      }
    }
  }
}
