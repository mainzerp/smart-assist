{
  "config": {
    "step": {
      "user": {
        "title": "OpenRouter API Configuration",
        "description": "Enter your OpenRouter API key. You can get one at {docs_url}\n\nAfter setup, add Conversation Agents or AI Tasks via the integration menu.",
        "data": {
          "api_key": "API Key"
        }
      }
    },
    "error": {
      "invalid_api_key": "Invalid API key. Please check and try again.",
      "cannot_connect": "Cannot connect to OpenRouter API.",
      "unknown": "An unexpected error occurred."
    },
    "abort": {
      "already_configured": "Smart Assist is already configured."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Smart Assist Settings",
        "description": "Configure global settings for Smart Assist.",
        "data": {
          "debug_logging": "Enable debug logging"
        },
        "data_description": {
          "debug_logging": "Enable verbose logging for debugging."
        }
      }
    }
  },
  "config_subentries": {
    "conversation": {
      "entry_type": "Conversation agent",
      "initiate_flow": {
        "user": "Add Conversation Agent",
        "reconfigure": "Reconfigure Conversation Agent"
      },
      "step": {
        "user": {
          "title": "Model Selection",
          "description": "Select the AI model for this conversation agent.\n\nAfter selecting a model, you can choose a specific provider in the next step.",
          "data": {
            "model": "Model"
          },
          "data_description": {
            "model": "Select an OpenRouter model or enter a custom model ID."
          }
        },
        "settings": {
          "title": "Agent Settings",
          "description": "Configure provider and behavior settings for this conversation agent.",
          "data": {
            "provider": "Provider",
            "temperature": "Temperature (0 = precise, 1 = creative)",
            "max_tokens": "Maximum response tokens",
            "language": "Response Language",
            "exposed_only": "Use only exposed entities",
            "confirm_critical": "Confirm critical actions (locks, alarms)",
            "max_history": "Maximum conversation history",
            "enable_web_search": "Enable web search (DuckDuckGo)",
            "enable_prompt_caching": "Enable prompt caching (reduces latency and cost)",
            "cache_ttl_extended": "Extended cache TTL (1 hour for Anthropic)",
            "enable_cache_warming": "Enable automatic cache warming",
            "cache_refresh_interval": "Cache refresh interval (minutes)",
            "clean_responses": "Clean responses for voice output",
            "ask_followup": "Ask follow-up questions",
            "calendar_context": "Proactive calendar reminders"
          },
          "data_description": {
            "provider": "Select a specific provider or use 'Automatic' for best price routing.",
            "temperature": "Lower values produce more consistent outputs, higher values are more creative.",
            "max_tokens": "Maximum number of tokens in the response.",
            "language": "Leave empty for auto-detect (uses HA language). Or enter any language (e.g., 'French', 'es-ES', 'Japanese').",
            "cache_ttl_extended": "Enable 1-hour cache instead of 5 minutes. Only applies to Anthropic models.",
            "enable_cache_warming": "Keeps the prompt cache warm by sending periodic requests. Incurs small additional API costs.",
            "cache_refresh_interval": "How often to refresh the cache (in minutes). Set below the cache TTL.",
            "clean_responses": "Makes responses TTS-friendly by removing emojis, markdown formatting, and URLs.",
            "ask_followup": "If enabled, the assistant will offer further help after completing actions.",
            "calendar_context": "Automatically mention upcoming calendar events. Note: Increases token usage."
          }
        },
        "prompt": {
          "title": "System Prompt",
          "description": "Customize the assistant's personality and behavior.",
          "data": {
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "user_system_prompt": "Personality and instructions for this conversation agent."
          }
        },
        "reconfigure": {
          "title": "Reconfigure Agent - Model",
          "description": "Select a new model for this agent.\n\nAfter confirming, you can update provider and other settings.",
          "data": {
            "model": "Model"
          }
        },
        "reconfigure_settings": {
          "title": "Reconfigure Agent - Settings",
          "description": "Update provider and behavior settings for this conversation agent.",
          "data": {
            "provider": "Provider",
            "temperature": "Temperature",
            "max_tokens": "Maximum response tokens",
            "language": "Response Language",
            "exposed_only": "Use only exposed entities",
            "confirm_critical": "Confirm critical actions",
            "max_history": "Maximum conversation history",
            "enable_web_search": "Enable web search",
            "enable_prompt_caching": "Enable prompt caching",
            "cache_ttl_extended": "Extended cache TTL",
            "enable_cache_warming": "Enable cache warming",
            "cache_refresh_interval": "Cache refresh interval",
            "clean_responses": "Clean responses for voice output",
            "ask_followup": "Ask follow-up questions",
            "calendar_context": "Proactive calendar reminders",
            "user_system_prompt": "System Prompt"
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Settings updated successfully."
      }
    },
    "ai_task": {
      "entry_type": "AI Task",
      "initiate_flow": {
        "user": "Add AI Task",
        "reconfigure": "Reconfigure AI Task"
      },
      "step": {
        "user": {
          "title": "Model Selection",
          "description": "Select the AI model for this task.\n\nAfter selecting a model, you can choose a specific provider in the next step.",
          "data": {
            "model": "Model"
          },
          "data_description": {
            "model": "Select an OpenRouter model or enter a custom model ID."
          }
        },
        "settings": {
          "title": "Task Settings",
          "description": "Configure provider and other settings for this AI task.",
          "data": {
            "provider": "Provider",
            "temperature": "Temperature (0 = precise, 1 = creative)",
            "max_tokens": "Maximum response tokens",
            "language": "Response Language",
            "exposed_only": "Use only exposed entities",
            "task_system_prompt": "System Prompt",
            "task_enable_prompt_caching": "Enable prompt caching",
            "task_enable_cache_warming": "Enable cache warming"
          },
          "data_description": {
            "provider": "Select a specific provider or use 'Automatic' for best price routing.",
            "temperature": "Lower values produce more consistent outputs, higher values are more creative.",
            "max_tokens": "Maximum number of tokens in the response.",
            "language": "Leave empty for auto-detect (uses HA language). Or enter any language (e.g., 'French', 'es-ES', 'Japanese').",
            "task_system_prompt": "Instructions for this AI task in automations.",
            "task_enable_prompt_caching": "Not recommended - background tasks are not time-critical.",
            "task_enable_cache_warming": "Not recommended - background tasks are not time-critical."
          }
        },
        "reconfigure": {
          "title": "Reconfigure Task - Model",
          "description": "Select a new model for this AI task.\n\nAfter confirming, you can update provider and other settings.",
          "data": {
            "model": "Model"
          }
        },
        "reconfigure_settings": {
          "title": "Reconfigure Task - Settings",
          "description": "Update provider and behavior settings for this AI task.",
          "data": {
            "provider": "Provider",
            "temperature": "Temperature",
            "max_tokens": "Maximum response tokens",
            "language": "Response Language",
            "exposed_only": "Use only exposed entities",
            "task_system_prompt": "System Prompt",
            "task_enable_prompt_caching": "Enable prompt caching",
            "task_enable_cache_warming": "Enable cache warming"
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Settings updated successfully."
      }
    }
  }
}
