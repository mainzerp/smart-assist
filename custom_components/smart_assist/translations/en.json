{
  "config": {
    "step": {
      "user": {
        "title": "OpenRouter API Configuration",
        "description": "Enter your OpenRouter API key. You can get one at {docs_url}\n\nAfter setup, add Conversation Agents or AI Tasks via the integration menu.",
        "data": {
          "api_key": "API Key"
        }
      }
    },
    "error": {
      "invalid_api_key": "Invalid API key. Please check and try again.",
      "cannot_connect": "Cannot connect to OpenRouter API.",
      "unknown": "An unexpected error occurred."
    },
    "abort": {
      "already_configured": "Smart Assist is already configured."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Smart Assist Settings",
        "description": "Configure global settings for Smart Assist.",
        "data": {
          "debug_logging": "Enable debug logging"
        },
        "data_description": {
          "debug_logging": "Enable verbose logging for debugging."
        }
      }
    }
  },
  "config_subentries": {
    "conversation": {
      "initiate_flow": {
        "user": "Add Conversation Agent"
      },
      "step": {
        "user": {
          "title": "Conversation Agent",
          "description": "Create a new conversation agent for Smart Assist.",
          "data": {
            "name": "Agent Name",
            "model": "Model (e.g. anthropic/claude-3-haiku)"
          },
          "data_description": {
            "name": "A unique name for this conversation agent.",
            "model": "Select an OpenRouter model or enter a custom model ID."
          }
        },
        "provider": {
          "title": "Provider Selection",
          "description": "Select a provider for **{model}**.\n\nProviders are sorted by price (cheapest first).",
          "data": {
            "provider": "Provider",
            "temperature": "Temperature (0 = precise, 1 = creative)",
            "max_tokens": "Maximum response tokens"
          },
          "data_description": {
            "provider": "Choose 'Automatic' for best price, or select a specific provider for prompt caching."
          }
        },
        "behavior": {
          "title": "Behavior Settings",
          "description": "Configure how this conversation agent behaves.",
          "data": {
            "language": "Response Language",
            "exposed_only": "Use only exposed entities",
            "confirm_critical": "Confirm critical actions (locks, alarms)",
            "max_history": "Maximum conversation history",
            "enable_web_search": "Enable web search (DuckDuckGo)",
            "enable_prompt_caching": "Enable prompt caching (reduces latency and cost)",
            "cache_ttl_extended": "Extended cache TTL (1 hour for Anthropic)",
            "enable_cache_warming": "Enable automatic cache warming",
            "cache_refresh_interval": "Cache refresh interval (minutes)",
            "clean_responses": "Clean responses for voice output",
            "ask_followup": "Ask follow-up questions"
          },
          "data_description": {
            "cache_ttl_extended": "Enable 1-hour cache instead of 5 minutes. Only applies to Anthropic models.",
            "enable_cache_warming": "Keeps the prompt cache warm by sending periodic requests. Incurs small additional API costs.",
            "cache_refresh_interval": "How often to refresh the cache (in minutes). Set below the cache TTL.",
            "clean_responses": "Makes responses TTS-friendly by removing emojis, markdown formatting, and URLs.",
            "ask_followup": "If enabled, the assistant will offer further help after completing actions."
          }
        },
        "prompt": {
          "title": "System Prompt",
          "description": "Customize the assistant's personality and behavior.",
          "data": {
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "user_system_prompt": "Personality and instructions for this conversation agent."
          }
        }
      }
    },
    "ai_task": {
      "initiate_flow": {
        "user": "Add AI Task"
      },
      "step": {
        "user": {
          "title": "AI Task",
          "description": "Create a new AI Task for use in automations.",
          "data": {
            "name": "Task Name",
            "model": "Model (e.g. anthropic/claude-3-haiku)"
          },
          "data_description": {
            "name": "A unique name for this AI task.",
            "model": "Select an OpenRouter model or enter a custom model ID."
          }
        },
        "provider": {
          "title": "Provider Selection",
          "description": "Select a provider for **{model}**.\n\nProviders are sorted by price (cheapest first).",
          "data": {
            "provider": "Provider",
            "temperature": "Temperature (0 = precise, 1 = creative)",
            "max_tokens": "Maximum response tokens"
          },
          "data_description": {
            "provider": "Choose 'Automatic' for best price, or select a specific provider."
          }
        },
        "settings": {
          "title": "Task Settings",
          "description": "Configure this AI task.",
          "data": {
            "task_system_prompt": "System Prompt",
            "task_enable_prompt_caching": "Enable prompt caching",
            "task_enable_cache_warming": "Enable cache warming"
          },
          "data_description": {
            "task_system_prompt": "Instructions for this AI task in automations.",
            "task_enable_prompt_caching": "Not recommended - background tasks are not time-critical.",
            "task_enable_cache_warming": "Not recommended - background tasks are not time-critical."
          }
        }
      }
    }
  }
}
