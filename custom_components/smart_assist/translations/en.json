{
  "config": {
    "step": {
      "user": {
        "title": "Select LLM Provider",
        "description": "Choose your preferred LLM provider.\n\n**Groq**: Ultra-fast inference with automatic caching (recommended)\n**OpenRouter**: Access to all models (Claude, GPT-4, Llama, etc.)\n**Ollama**: Local, private inference (no cloud, no API key needed)",
        "data": {
          "llm_provider": "LLM Provider"
        }
      },
      "api_key": {
        "title": "API Key",
        "description": "Enter your API key. You can get one at {docs_url}",
        "data": {
          "api_key": "OpenRouter API Key",
          "groq_api_key": "Groq API Key",
          "ollama_url": "Ollama Server URL",
          "ollama_model": "Ollama Model",
          "ollama_keep_alive": "Keep Model Loaded",
          "ollama_num_ctx": "Context Window Size",
          "ollama_timeout": "Request Timeout (seconds)"
        },
        "data_description": {
          "ollama_url": "URL of your Ollama server (default: http://localhost:11434)",
          "ollama_model": "Select a model from your local Ollama installation",
          "ollama_keep_alive": "How long to keep the model in memory (-1 = forever)",
          "ollama_num_ctx": "Context window size in tokens (default: 8192)",
          "ollama_timeout": "Maximum time to wait for a response (default: 120s)"
        }
      },
      "reconfigure": {
        "title": "Update API Keys & Ollama Settings",
        "description": "Update your API keys and Ollama settings. Leave API key fields empty to keep existing values.\n\n**API Key Status:**\n- Groq: {groq_status}\n- OpenRouter: {openrouter_status}\n- Ollama: {ollama_status}",
        "data": {
          "groq_api_key": "Groq API Key",
          "api_key": "OpenRouter API Key",
          "ollama_url": "Ollama Server URL",
          "ollama_num_ctx": "Ollama: Context Window Size",
          "ollama_keep_alive": "Ollama: Keep Model Loaded",
          "ollama_timeout": "Ollama: Request Timeout (seconds)"
        },
        "data_description": {
          "groq_api_key": "Enter a new Groq API key or leave empty to keep the current one.",
          "api_key": "Enter a new OpenRouter API key or leave empty to keep the current one.",
          "ollama_url": "Enter a new Ollama URL or leave empty to keep the current one.",
          "ollama_num_ctx": "Context window size in tokens. Larger values allow more context but use more RAM.",
          "ollama_keep_alive": "How long to keep the model loaded in memory after a request.",
          "ollama_timeout": "Maximum time to wait for Ollama to respond (in seconds)."
        }
      }
    },
    "error": {
      "invalid_api_key": "Invalid OpenRouter API key. Please check and try again.",
      "invalid_groq_api_key": "Invalid Groq API key. Please check and try again.",
      "ollama_connection_failed": "Cannot connect to Ollama server. Make sure Ollama is running at the specified URL.",
      "ollama_not_configured": "Ollama is not configured. Please add Ollama configuration in the main integration settings.",
      "groq_api_key_required": "Groq API key is required for Groq provider.",
      "openrouter_api_key_required": "OpenRouter API key is required for OpenRouter provider.",
      "structured_output_invalid_json": "Sorry, I could not generate valid structured output for this task.",
      "structured_output_schema_mismatch": "Sorry, the structured result did not match the required format.",
      "no_api_key": "At least one API key (OpenRouter or Groq) is required.",
      "cannot_connect": "Cannot connect to API.",
      "unknown": "An unexpected error occurred."
    },
    "abort": {
      "already_configured": "Smart Assist is already configured."
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Smart Assist Settings",
        "description": "Configure global settings for Smart Assist.",
        "data": {
          "debug_logging": "Enable debug logging",
          "enable_cancel_handler": "Cancel intent handler"
        },
        "data_description": {
          "debug_logging": "Enable verbose logging for debugging.",
          "enable_cancel_handler": "Returns a TTS-spoken confirmation when the user says 'Cancel' or 'Never mind'. Fixes voice satellites hanging on empty cancel responses. Uses the LLM to generate a brief, natural response."
        }
      }
    }
  },
  "config_subentries": {
    "conversation": {
      "entry_type": "Conversation agent",
      "initiate_flow": {
        "user": "Add Conversation Agent",
        "reconfigure": "Reconfigure Conversation Agent"
      },
      "step": {
        "user": {
          "title": "LLM Provider Selection",
          "description": "Select the LLM provider for this conversation agent.\n\n**OpenRouter**: Access to all models (Claude, GPT-4, Llama, etc.) via a unified API.\n**Groq**: Direct connection for ultra-fast inference with automatic caching.\n**Ollama**: Local, private inference without cloud dependency.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          },
          "data_description": {
            "llm_provider": "Select OpenRouter for model variety, Groq for fastest inference, or Ollama for local privacy.",
            "groq_api_key": "Enter your Groq API key (get one at console.groq.com)."
          }
        },
        "model": {
          "title": "Model Selection",
          "description": "Select the AI model for this conversation agent.",
          "data": {
            "model": "Model"
          },
          "data_description": {
            "model": "Select a model or enter a custom model ID."
          }
        },
        "settings": {
          "title": "Agent Settings",
          "description": "Configure provider and behavior settings for this conversation agent.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperature (0 = precise, 1 = creative)",
            "max_tokens": "Maximum response tokens",
            "max_history": "Maximum conversation history",
            "language": "Response Language",
            "clean_responses": "Clean responses for voice output",
            "ask_followup": "Ask follow-up questions",
            "exposed_only": "Use only exposed entities",
            "entity_discovery_mode": "Entity Discovery Mode",
            "confirm_critical": "Confirm critical actions (locks, alarms)",
            "tool_max_retries": "Tool max retries",
            "tool_latency_budget_ms": "Tool latency budget (ms)",
            "enable_web_search": "Enable web search (DuckDuckGo)",
            "calendar_context": "Proactive calendar reminders",
            "enable_memory": "Enable user memory & personalization",
            "enable_agent_memory": "Enable agent auto-learning",
            "enable_presence_heuristic": "Enable presence-based user detection",
            "enable_request_history_content": "Store request history content",
            "history_retention_days": "Request history retention (days)",
            "history_redact_patterns": "Request history redaction patterns",
            "enable_cache_warming": "Enable automatic cache warming",
            "cache_refresh_interval": "Cache refresh interval (minutes)",
            "cancel_intent_agent": "Use as cancel intent handler"
          },
          "data_description": {
            "provider": "OpenRouter only: Select a specific provider or use 'Automatic' for best price routing.",
            "temperature": "Lower values produce more consistent outputs, higher values are more creative.",
            "max_tokens": "Maximum number of tokens in the response.",
            "max_history": "Number of previous messages kept for context. Higher values use more tokens.",
            "language": "'auto' = uses HA language. Or enter any language (e.g., 'French', 'es-ES', 'Japanese').",
            "clean_responses": "Makes responses TTS-friendly by removing emojis, markdown formatting, and URLs.",
            "ask_followup": "If enabled, the assistant will offer further help after completing actions.",
            "exposed_only": "Only controls entities that are explicitly exposed in Home Assistant. Disable to access all entities.",
            "entity_discovery_mode": "Full Index: All entities listed in prompt (best for small setups). Smart Discovery: No entity list -- entities discovered on-demand via tool calls (saves tokens for large setups).",
            "confirm_critical": "Asks for confirmation before locking doors, arming alarms, or other security-critical actions.",
            "tool_max_retries": "Maximum retry attempts for failed tool calls per request.",
            "tool_latency_budget_ms": "Per-tool timeout budget in milliseconds. Timed out calls are marked as failed.",
            "enable_web_search": "Allows the assistant to search the web via DuckDuckGo for current information.",
            "calendar_context": "Automatically mention upcoming calendar events. Note: Increases token usage.",
            "enable_memory": "Allows the assistant to remember user preferences, names, and instructions across conversations.",
            "enable_agent_memory": "Allows the assistant to learn from interactions and save its own observations (patterns, habits, system insights). Requires memory to be enabled.",
            "enable_presence_heuristic": "Automatically detect which user is speaking based on who is home. Only works when exactly one person is home.",
            "enable_request_history_content": "If enabled, user input and responses are stored in request history. If disabled, content fields remain empty.",
            "history_retention_days": "How many days request history entries are kept before automatic cleanup.",
            "history_redact_patterns": "Optional terms or regex patterns (one per line or comma-separated) replaced with [REDACTED] in stored history content.",
            "enable_cache_warming": "Keeps the prompt cache warm by sending periodic requests. Incurs small additional API costs.",
            "cache_refresh_interval": "How often to refresh the cache (in minutes). Set below the cache TTL.",
            "cancel_intent_agent": "Use this agent to generate the spoken cancel/nevermind confirmation. Only one agent should have this enabled. If none is selected, the first available agent is used."
          }
        },
        "prompt": {
          "title": "System Prompt",
          "description": "Customize the assistant's personality and behavior.",
          "data": {
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "user_system_prompt": "Personality and instructions for this conversation agent."
          }
        },
        "reconfigure": {
          "title": "Reconfigure Agent - LLM Provider",
          "description": "Select the LLM provider for this agent.\n\nAfter confirming, you can update model and other settings.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          }
        },
        "reconfigure_model": {
          "title": "Reconfigure Agent - Model",
          "description": "Select a new model for this agent.",
          "data": {
            "model": "Model"
          }
        },
        "reconfigure_settings": {
          "title": "Reconfigure Agent - Settings",
          "description": "Update provider and behavior settings for this conversation agent.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperature",
            "max_tokens": "Maximum response tokens",
            "max_history": "Maximum conversation history",
            "language": "Response Language",
            "clean_responses": "Clean responses for voice output",
            "ask_followup": "Ask follow-up questions",
            "exposed_only": "Use only exposed entities",
            "entity_discovery_mode": "Entity Discovery Mode",
            "confirm_critical": "Confirm critical actions",
            "tool_max_retries": "Tool max retries",
            "tool_latency_budget_ms": "Tool latency budget (ms)",
            "enable_web_search": "Enable web search",
            "calendar_context": "Proactive calendar reminders",
            "enable_memory": "Enable user memory",
            "enable_agent_memory": "Enable agent auto-learning",
            "enable_presence_heuristic": "Presence-based user detection",
            "enable_request_history_content": "Store request history content",
            "history_retention_days": "Request history retention (days)",
            "history_redact_patterns": "Request history redaction patterns",
            "enable_cache_warming": "Enable cache warming",
            "cache_refresh_interval": "Cache refresh interval",
            "cancel_intent_agent": "Use as cancel intent handler",
            "user_system_prompt": "System Prompt"
          },
          "data_description": {
            "provider": "OpenRouter only: Select a specific provider or use 'Automatic' for best price routing.",
            "temperature": "Lower values produce more consistent outputs, higher values are more creative.",
            "max_tokens": "Maximum number of tokens in the response.",
            "language": "'auto' = uses HA language. Or enter any language (e.g., 'French', 'es-ES', 'Japanese').",
            "exposed_only": "Only controls entities that are explicitly exposed in Home Assistant. Disable to access all entities.",
            "entity_discovery_mode": "Full Index: All entities listed in prompt (best for small setups). Smart Discovery: No entity list -- entities discovered on-demand via tool calls (saves tokens for large setups).",
            "confirm_critical": "Asks for confirmation before locking doors, arming alarms, or other security-critical actions.",
            "tool_max_retries": "Maximum retry attempts for failed tool calls per request.",
            "tool_latency_budget_ms": "Per-tool timeout budget in milliseconds. Timed out calls are marked as failed.",
            "max_history": "Number of previous messages kept for context. Higher values use more tokens.",
            "enable_web_search": "Allows the assistant to search the web via DuckDuckGo for current information.",
            "enable_cache_warming": "Keeps the prompt cache warm by sending periodic requests. Incurs small additional API costs.",
            "cache_refresh_interval": "How often to refresh the cache (in minutes). Set below the cache TTL.",
            "clean_responses": "Makes responses TTS-friendly by removing emojis, markdown formatting, and URLs.",
            "ask_followup": "If enabled, the assistant will offer further help after completing actions.",
            "calendar_context": "Automatically mention upcoming calendar events. Note: Increases token usage.",
            "enable_memory": "Allows the assistant to remember user preferences, names, and instructions across conversations.",
            "enable_agent_memory": "Allows the assistant to learn from interactions and save its own observations (patterns, habits, system insights). Requires memory to be enabled.",
            "enable_presence_heuristic": "Automatically detect which user is speaking based on who is home. Only works when exactly one person is home.",
            "enable_request_history_content": "If enabled, user input and responses are stored in request history. If disabled, content fields remain empty.",
            "history_retention_days": "How many days request history entries are kept before automatic cleanup.",
            "history_redact_patterns": "Optional terms or regex patterns (one per line or comma-separated) replaced with [REDACTED] in stored history content.",
            "user_system_prompt": "Personality and instructions for this conversation agent.",
            "cancel_intent_agent": "Use this agent to generate the spoken cancel/nevermind confirmation. Only one agent should have this enabled. If none is selected, the first available agent is used."
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Settings updated successfully.",
        "no_api_keys_configured": "No API keys configured. Please add at least one API key in the main integration settings."
      },
      "error": {
        "groq_api_key_required": "Groq API key is required for Groq provider.",
        "openrouter_api_key_required": "OpenRouter API key is required for OpenRouter provider.",
        "ollama_not_configured": "Ollama is not configured. Please add Ollama configuration in the main integration settings."
      }
    },
    "ai_task": {
      "entry_type": "AI Task",
      "initiate_flow": {
        "user": "Add AI Task",
        "reconfigure": "Reconfigure AI Task"
      },
      "step": {
        "user": {
          "title": "LLM Provider Selection",
          "description": "Select the LLM provider for this AI task.\n\n**OpenRouter**: Access to all models via a unified API.\n**Groq**: Direct connection for ultra-fast inference.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          },
          "data_description": {
            "llm_provider": "Select OpenRouter for model variety or Groq for fastest inference.",
            "groq_api_key": "Enter your Groq API key (get one at console.groq.com)."
          }
        },
        "model": {
          "title": "Model Selection",
          "description": "Select the AI model for this task.",
          "data": {
            "model": "Model"
          },
          "data_description": {
            "model": "Select a model or enter a custom model ID."
          }
        },
        "settings": {
          "title": "Task Settings",
          "description": "Configure provider and other settings for this AI task.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperature (0 = precise, 1 = creative)",
            "max_tokens": "Maximum response tokens",
            "language": "Response Language",
            "exposed_only": "Use only exposed entities",
            "tool_max_retries": "Tool max retries",
            "tool_latency_budget_ms": "Tool latency budget (ms)",
            "task_allow_control": "Allow control execution",
            "task_allow_lock_control": "Allow lock control",
            "task_system_prompt": "System Prompt",
            "task_enable_cache_warming": "Enable cache warming"
          },
          "data_description": {
            "provider": "OpenRouter only: Select a specific provider or use 'Automatic' for best price routing.",
            "temperature": "Lower values produce more consistent outputs, higher values are more creative.",
            "max_tokens": "Maximum number of tokens in the response.",
            "language": "'auto' = uses HA language. Or enter any language (e.g., 'French', 'es-ES', 'Japanese').",
            "task_system_prompt": "Instructions for this AI task in automations.",
            "exposed_only": "Only controls entities that are explicitly exposed in Home Assistant. Disable to access all entities.",
            "tool_max_retries": "Maximum retry attempts for failed tool calls per request.",
            "tool_latency_budget_ms": "Per-tool timeout budget in milliseconds. Timed out calls are marked as failed.",
            "task_allow_control": "If disabled, this AI task cannot execute any control tool call.",
            "task_allow_lock_control": "If disabled, this AI task cannot control lock.* entities (only applies when control execution is enabled).",
            "task_enable_cache_warming": "Not recommended - background tasks are not time-critical."
          }
        },
        "reconfigure": {
          "title": "Reconfigure Task - LLM Provider",
          "description": "Select the LLM provider for this task.\n\nAfter confirming, you can update model and other settings.",
          "data": {
            "llm_provider": "LLM Provider",
            "groq_api_key": "Groq API Key"
          }
        },
        "reconfigure_model": {
          "title": "Reconfigure Task - Model",
          "description": "Select a new model for this AI task.",
          "data": {
            "model": "Model"
          }
        },
        "reconfigure_settings": {
          "title": "Reconfigure Task - Settings",
          "description": "Update provider and behavior settings for this AI task.",
          "data": {
            "provider": "Provider Routing",
            "temperature": "Temperature",
            "max_tokens": "Maximum response tokens",
            "language": "Response Language",
            "exposed_only": "Use only exposed entities",
            "tool_max_retries": "Tool max retries",
            "tool_latency_budget_ms": "Tool latency budget (ms)",
            "task_allow_control": "Allow control execution",
            "task_allow_lock_control": "Allow lock control",
            "task_system_prompt": "System Prompt",
            "task_enable_cache_warming": "Enable cache warming"
          },
          "data_description": {
            "provider": "OpenRouter only: Select a specific provider or use 'Automatic' for best price routing.",
            "temperature": "Lower values produce more consistent outputs, higher values are more creative.",
            "max_tokens": "Maximum number of tokens in the response.",
            "language": "'auto' = uses HA language. Or enter any language (e.g., 'French', 'es-ES', 'Japanese').",
            "exposed_only": "Only controls entities that are explicitly exposed in Home Assistant. Disable to access all entities.",
            "task_system_prompt": "Instructions for this AI task in automations.",
            "tool_max_retries": "Maximum retry attempts for failed tool calls per request.",
            "tool_latency_budget_ms": "Per-tool timeout budget in milliseconds. Timed out calls are marked as failed.",
            "task_allow_control": "If disabled, this AI task cannot execute any control tool call.",
            "task_allow_lock_control": "If disabled, this AI task cannot control lock.* entities (only applies when control execution is enabled).",
            "task_enable_cache_warming": "Not recommended - background tasks are not time-critical."
          }
        }
      },
      "abort": {
        "reconfigure_successful": "Settings updated successfully.",
        "no_api_keys_configured": "No API keys configured. Please add at least one API key in the main integration settings."
      },
      "error": {
        "groq_api_key_required": "Groq API key is required for Groq provider.",
        "openrouter_api_key_required": "OpenRouter API key is required for OpenRouter provider.",
        "ollama_not_configured": "Ollama is not configured. Please add Ollama configuration in the main integration settings."
      }
    }
  },
  "selector": {
    "entity_discovery_mode": {
      "options": {
        "full_index": "Full Index (all entities in prompt)",
        "smart_discovery": "Smart Discovery (on-demand, saves tokens)"
      }
    },
    "alarm_execution_mode": {
      "options": {
        "managed_only": "Managed only",
        "direct_only": "Direct only",
        "hybrid": "Hybrid"
      }
    }
  }
}
